{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 9\n",
    "Let's predict the future.\n",
    "\n",
    "## Part 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import util\n",
    "\n",
    "# Colors to visualize the labeling\n",
    "COLORS = np.array([(0,0,0), (255,0,0), (0,255,0), (255,255,0), (0,0,255), (255,255,255)], dtype=np.uint8)\n",
    "CROP_SIZE = 64\n",
    "N_ACTION = 5\n",
    "\n",
    "offsets = [0, 6, 15, 30, 60, 120]\n",
    "\n",
    "def parser(record):\n",
    "    # Parse the TF record\n",
    "    \n",
    "    feature ={\n",
    "        'height': tf.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.FixedLenFeature([], tf.int64),\n",
    "        'channels': tf.FixedLenFeature([], tf.int64),\n",
    "        'n_future': tf.FixedLenFeature([], tf.int64),\n",
    "        'action': tf.FixedLenFeature([], tf.int64),\n",
    "        'image_raw': tf.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    values = {'position' : np.float32, 'is_dying': np.int64, 'on_ground': np.int64, 'coins': np.int64}\n",
    "    for k,v in enumerate(values):\n",
    "        t = values[v]\n",
    "        for j, o in enumerate(offsets):\n",
    "            feature[v+'_%d'%j] = tf.FixedLenFeature([], t)\n",
    "\n",
    "    parsed = tf.parse_single_example(record, features=feature)\n",
    "     \n",
    "    # Load the data and format it\n",
    "    W = tf.cast(parsed['width'], tf.int32)\n",
    "    H = tf.cast(parsed['height'], tf.int32)\n",
    "    C = tf.cast(parsed['channels'], tf.int32)\n",
    "    A = tf.cast(parsed['action'], tf.int32)\n",
    "    actions = tf.stack([tf.bitwise.bitwise_and(A, (1<<i)) > 0 for i in range(N_ACTION)])\n",
    "    image = tf.reshape(tf.decode_raw(parsed[\"image_raw\"], tf.uint8), [H,W,C])\n",
    "    \n",
    "    current_position = tf.cast(parsed['position_0'], tf.float32)\n",
    "    current_is_dying = tf.cast(parsed['is_dying_0'], tf.bool)\n",
    "    current_coins = tf.cast(parsed['coins_0'], tf.float32)\n",
    "    \n",
    "    future_position = tf.stack([tf.cast(parsed['position_%d'%o], tf.float32) for o in range(1,len(offsets))])\n",
    "    future_is_dying = tf.stack([tf.cast(parsed['is_dying_%d'%o], tf.bool) for o in range(1,len(offsets))])\n",
    "    future_coins = tf.stack([tf.cast(parsed['coins_%d'%o], tf.float32) for o in range(1,len(offsets))])\n",
    "    \n",
    "    ## No data augmentation this time, as it might affect the future\n",
    "    return image, actions, current_position, current_is_dying, current_coins, future_position, future_is_dying, future_coins\n",
    "\n",
    "def load_dataset(tfrecord):\n",
    "    # Load the dataset\n",
    "    dataset = tf.contrib.data.TFRecordDataset(tfrecord)\n",
    "\n",
    "    # Parse the tf record entries\n",
    "    dataset = dataset.map(parser, num_threads=8, output_buffer_size=1024)\n",
    "\n",
    "    # Shuffle the data, batch it and run this for multiple epochs\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(32)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Define your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of variables used  15559\n"
     ]
    }
   ],
   "source": [
    "# Create a new log directory (if you run low on disk space you can either disable this or delete old logs)\n",
    "# run: `tensorboard --logdir log` to see all the nice summaries\n",
    "for n_model in range(1000):\n",
    "    LOG_DIR = 'log/model_%d'%n_model\n",
    "    from os import path\n",
    "    if not path.exists(LOG_DIR):\n",
    "        break\n",
    "\n",
    "# Lets clear the tensorflow graph, so that you don't have to restart the notebook every time you change the network\n",
    "tf.reset_default_graph()\n",
    "\n",
    "TF_COLORS = tf.constant(COLORS)\n",
    "\n",
    "train_data = load_dataset('future_train.tfrecord')\n",
    "valid_data = load_dataset('future_val.tfrecord')\n",
    "\n",
    "# Create an iterator for the datasets\n",
    "# The iterator allows us to quickly switch between training and validataion\n",
    "iterator = tf.contrib.data.Iterator.from_structure(train_data.output_types, ((None,64,64,9), (None,N_ACTION), (None,), (None,), (None,), (None,len(offsets)-1), (None,len(offsets)-1), (None,len(offsets)-1)))\n",
    "\n",
    "# and fetch the next images from the dataset (every time next_image is evaluated a new image set of 32 images is returned)\n",
    "image, action, current_position, current_is_dying, current_coins, future_position, future_is_dying, future_coins = iterator.get_next()\n",
    "\n",
    "# Define operations that switch between train and valid\n",
    "switch_train_op = iterator.make_initializer(train_data)\n",
    "switch_valid_op = iterator.make_initializer(valid_data)\n",
    "\n",
    "# Convert the input and label\n",
    "image = tf.identity(image, name='images')\n",
    "image = tf.cast(image, tf.float32)\n",
    "action = tf.identity(tf.cast(action, tf.int32), name='action')\n",
    "\n",
    "current_position = tf.identity(current_position, name='current_position')\n",
    "current_is_dying = tf.identity(current_is_dying, name='current_is_dying')\n",
    "current_coins = tf.identity(current_coins, name='current_coins')\n",
    "\n",
    "future_position = tf.identity(future_position, name='future_position')\n",
    "future_is_dying = tf.identity(future_is_dying, name='future_is_dying')\n",
    "future_coins = tf.identity(future_coins, name='future_coins')\n",
    "\n",
    "# Whiten the image\n",
    "white_image = (image - 100.) / 72.\n",
    "h = white_image\n",
    "\n",
    "# TODO: Define your convnet and loss here\n",
    "# In preparation for the next homework you might want to make this network small and efficient.\n",
    "training = tf.placeholder_with_default(False, (), name='training')\n",
    "\n",
    "# Build the network out of a few convolutional layers\n",
    "h = tf.contrib.layers.conv2d(h, 5, (5,5), stride=1, weights_regularizer=tf.nn.l2_loss)\n",
    "h = tf.layers.batch_normalization(h, center=False, scale=False, training=training)   \n",
    "h = tf.contrib.layers.conv2d(h, 10, (5,5), stride=1, weights_regularizer=tf.nn.l2_loss)\n",
    "h = tf.layers.batch_normalization(h, center=False, scale=False, training=training)\n",
    "h = tf.contrib.layers.conv2d(h, 9, (5,5), stride=1, weights_regularizer=tf.nn.l2_loss)\n",
    "h = tf.layers.batch_normalization(h, center=False, scale=False, training=training)\n",
    "\n",
    "# Hook up a fully connected layer to predict the action\n",
    "fc = tf.contrib.layers.fully_connected(h, 9, activation_fn=None)\n",
    "\n",
    "# Combine the action and the output of the conv layer\n",
    "h = tf.add(fc, h)\n",
    "\n",
    "output = tf.identity(h, name='output')\n",
    "# Use a cross entropy for the action and is_dying, L2 for position and coin.\n",
    "# sigmoid for action and is dying\n",
    "# TODO: define losses here\n",
    "action_logit = tf.contrib.layers.conv2d(h, 5, (5,5), stride=2, weights_regularizer=tf.nn.l2_loss)\n",
    "action_logit = tf.contrib.layers.conv2d(action_logit, 5, (5,5), stride=2, weights_regularizer=tf.nn.l2_loss)\n",
    "action_logit = tf.contrib.layers.conv2d(action_logit, 5, (5,5), stride=2, weights_regularizer=tf.nn.l2_loss)\n",
    "action_logit = tf.contrib.layers.conv2d(action_logit, 5, (5,5), stride=2, weights_regularizer=tf.nn.l2_loss)\n",
    "action_logit = tf.contrib.layers.conv2d(action_logit, 5, (5,5), stride=2, weights_regularizer=tf.nn.l2_loss)\n",
    "action_logit = tf.contrib.layers.conv2d(action_logit, 5, (5,5), stride=2, weights_regularizer=tf.nn.l2_loss)\n",
    "action_logit = tf.contrib.layers.flatten(action_logit)\n",
    "\n",
    "future_is_dying_logit = tf.contrib.layers.conv2d(h, 5, (5,5), stride=64, weights_regularizer=tf.nn.l2_loss)\n",
    "future_is_dying_logit = tf.contrib.layers.flatten(future_is_dying_logit)\n",
    "\n",
    "future_position_logit = tf.contrib.layers.conv2d(h, 5, (5,5), stride=2, weights_regularizer=tf.nn.l2_loss)\n",
    "future_position_logit = tf.contrib.layers.conv2d(future_position_logit, 5, (5,5), stride=2, weights_regularizer=tf.nn.l2_loss)\n",
    "future_position_logit = tf.contrib.layers.conv2d(future_position_logit, 5, (5,5), stride=2, weights_regularizer=tf.nn.l2_loss)\n",
    "future_position_logit = tf.contrib.layers.conv2d(future_position_logit, 5, (5,5), stride=2, weights_regularizer=tf.nn.l2_loss)\n",
    "future_position_logit = tf.contrib.layers.conv2d(future_position_logit, 5, (5,5), stride=2, weights_regularizer=tf.nn.l2_loss)\n",
    "future_position_logit = tf.contrib.layers.conv2d(future_position_logit, 5, (5,5), stride=2, weights_regularizer=tf.nn.l2_loss)\n",
    "future_position_logit = tf.contrib.layers.flatten(future_position_logit)\n",
    "\n",
    "future_coins_logit = tf.contrib.layers.conv2d(h, 5, (5,5), stride=64, weights_regularizer=tf.nn.l2_loss)\n",
    "future_coins_logit = tf.contrib.layers.flatten(future_coins_logit)\n",
    "\n",
    "coins_loss = tf.reduce_mean(tf.abs(future_coins_logit - future_coins))\n",
    "position_loss = tf.reduce_mean(tf.abs(future_position_logit - future_position))\n",
    "is_dying_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=future_is_dying_logit, labels=future_is_dying))\n",
    "#action_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=action_logit, labels=action))\n",
    "action = tf.cast(action, tf.float32)\n",
    "action_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=action_logit, labels=action))\n",
    "\n",
    "#output = tf.identity(h, name='output')\n",
    "\n",
    "loss = 0.05*coins_loss + position_loss + is_dying_loss + action_loss\n",
    "\n",
    "# a binary vector of size 5 for each image in the batch (DO NOT USE action TO PREDICT THIS!)\n",
    "pred_action = tf.identity(action_logit > 0.5, name='predicted_action')\n",
    "\n",
    "# vectors of size (5) for each image in the batch (use action AND current_position, current_is_dying, current_coins TO PREDICT THIS)\n",
    "# Hint: for some variables you might want to make them relative to current_..., for others not\n",
    "pred_is_dying = tf.identity(future_is_dying_logit > 0.5, name='predicted_is_dying')\n",
    "pred_position = tf.identity(future_position_logit, name='predicted_position')\n",
    "pred_coins = tf.identity(future_coins_logit, name='predicted_coins')\n",
    "\n",
    "action_acc = tf.reduce_mean(tf.cast(tf.equal(tf.cast(pred_action, tf.float32), tf.cast(action, tf.float32)), tf.float32))\n",
    "dying_acc = tf.reduce_mean(tf.cast(tf.equal(tf.cast(pred_is_dying, tf.float32), tf.cast(future_is_dying, tf.float32)), tf.float32))\n",
    "\n",
    "# Let's weight the regularization loss down, otherwise it will hurt the model performance\n",
    "# You can tune this weight if you wish\n",
    "regularization_loss = tf.losses.get_regularization_loss()\n",
    "total_loss = loss + 1e-6 * regularization_loss\n",
    "\n",
    "# Adam will likely converge much faster than SGD for this assignment.\n",
    "optimizer = tf.train.AdamOptimizer(0.001, 0.9, 0.999)\n",
    "\n",
    "# use that optimizer on your loss function (control_dependencies makes sure any \n",
    "# batch_norm parameters are properly updated)\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    opt = optimizer.minimize(total_loss)\n",
    "\n",
    "# Let's define some summaries for tensorboard\n",
    "tf.summary.image('image1', image[:,:,:,:3], max_outputs=3)\n",
    "tf.summary.image('image2', image[:,:,:,3:6], max_outputs=3)\n",
    "tf.summary.image('image3', image[:,:,:,6:9], max_outputs=3)\n",
    "tf.summary.scalar('action_loss', tf.placeholder(tf.float32, name='action_loss'))\n",
    "tf.summary.scalar('is_dying_loss', tf.placeholder(tf.float32, name='is_dying_loss'))\n",
    "tf.summary.scalar('position_loss', tf.placeholder(tf.float32, name='position_loss'))\n",
    "tf.summary.scalar('coins_loss', tf.placeholder(tf.float32, name='coins_loss'))\n",
    "tf.summary.scalar('loss', tf.placeholder(tf.float32, name='loss'))\n",
    "tf.summary.scalar('val_loss', tf.placeholder(tf.float32, name='val_loss'))\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR, tf.get_default_graph())\n",
    "\n",
    "# Let's compute the model size\n",
    "print( \"Total number of variables used \", np.sum([v.get_shape().num_elements() for v in tf.trainable_variables()]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Training\n",
    "\n",
    "Training might take up to 20 min depending on your architecture (and if you have a GPU or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 0.786344 VL: 0.757008 A: 0.825 D: 1.0 P: 0.0371452 C: 0.625108\n",
      "L: 0.766376 VL: 0.72958 A: 0.86875 D: 1.0 P: 0.041512 C: 0.02636\n",
      "L: 0.753649 VL: 0.744067 A: 0.85 D: 1.0 P: 0.0388828 C: 0.0\n",
      "L: 0.747551 VL: 0.749057 A: 0.76875 D: 0.99375 P: 0.0478214 C: 0.0\n",
      "L: 0.747945 VL: 0.768114 A: 0.76875 D: 1.0 P: 0.0551077 C: 0.0\n",
      "L: 0.736389 VL: 0.741619 A: 0.8875 D: 1.0 P: 0.0238293 C: 0.0\n",
      "L: 0.756095 VL: 0.727549 A: 0.85625 D: 1.0 P: 0.0316743 C: 0.0\n",
      "L: 0.742134 VL: 0.719847 A: 0.85 D: 1.0 P: 0.0541572 C: 0.0\n",
      "L: 0.738061 VL: 0.771067 A: 0.85 D: 1.0 P: 0.028917 C: 0.0\n",
      "L: 0.734507 VL: 0.772427 A: 0.80625 D: 1.0 P: 0.0272039 C: 0.0\n",
      "L: 0.742112 VL: 0.718529 A: 0.8375 D: 1.0 P: 0.029493 C: 0.0\n",
      "L: 0.737246 VL: 0.730207 A: 0.8875 D: 0.99375 P: 0.0668796 C: 0.0\n",
      "L: 0.742025 VL: 0.772011 A: 0.79375 D: 0.99375 P: 0.0388284 C: 0.0\n",
      "L: 0.747275 VL: 0.785453 A: 0.85 D: 1.0 P: 0.0340083 C: 0.0\n",
      "L: 0.754001 VL: 0.727422 A: 0.84375 D: 1.0 P: 0.0503584 C: 0.0\n",
      "L: 0.742318 VL: 0.725503 A: 0.81875 D: 1.0 P: 0.0313389 C: 0.0\n",
      "L: 0.736892 VL: 0.735151 A: 0.86875 D: 1.0 P: 0.0336844 C: 0.0\n",
      "L: 0.735627 VL: 0.739925 A: 0.85 D: 1.0 P: 0.0339329 C: 0.0\n",
      "L: 0.743094 VL: 0.707837 A: 0.8125 D: 1.0 P: 0.0349876 C: 0.0\n",
      "L: 0.753571 VL: 0.723422 A: 0.8875 D: 1.0 P: 0.0203836 C: 0.0\n",
      "L: 0.750774 VL: 0.749398 A: 0.84375 D: 1.0 P: 0.0390328 C: 0.0\n",
      "L: 0.745118 VL: 0.722023 A: 0.81875 D: 1.0 P: 0.0543672 C: 0.0\n",
      "L: 0.73465 VL: 0.718151 A: 0.86875 D: 1.0 P: 0.0251582 C: 0.0\n",
      "L: 0.741391 VL: 0.72315 A: 0.84375 D: 1.0 P: 0.0516487 C: 0.0\n",
      "L: 0.736409 VL: 0.713809 A: 0.80625 D: 0.99375 P: 0.0214598 C: 0.0\n",
      "L: 0.730127 VL: 0.781498 A: 0.85625 D: 0.99375 P: 0.0205986 C: 0.0\n",
      "L: 0.734936 VL: 0.713368 A: 0.88125 D: 0.99375 P: 0.0353648 C: 0.0\n",
      "L: 0.735932 VL: 0.710519 A: 0.8 D: 1.0 P: 0.0203952 C: 0.0\n",
      "L: 0.722358 VL: 0.730549 A: 0.85625 D: 0.9875 P: 0.0446662 C: 0.0\n",
      "L: 0.7231 VL: 0.713606 A: 0.81875 D: 1.0 P: 0.0332119 C: 0.0\n",
      "L: 0.724566 VL: 0.706993 A: 0.81875 D: 1.0 P: 0.0195878 C: 0.0\n",
      "L: 0.718677 VL: 0.743327 A: 0.81875 D: 1.0 P: 0.0168821 C: 0.0\n",
      "L: 0.713252 VL: 0.784659 A: 0.86875 D: 1.0 P: 0.0312514 C: 0.0\n",
      "L: 0.718522 VL: 0.712262 A: 0.81875 D: 1.0 P: 0.0232995 C: 0.0\n",
      "L: 0.719667 VL: 0.717349 A: 0.80625 D: 1.0 P: 0.018235 C: 0.0\n",
      "L: 0.710945 VL: 0.7051 A: 0.8125 D: 1.0 P: 0.0323867 C: 0.0\n",
      "L: 0.719758 VL: 0.754844 A: 0.9 D: 1.0 P: 0.0219243 C: 0.0\n",
      "L: 0.720634 VL: 0.71252 A: 0.85 D: 1.0 P: 0.0182712 C: 0.0\n",
      "L: 0.719562 VL: 0.730126 A: 0.85625 D: 1.0 P: 0.0574252 C: 0.0\n",
      "L: 0.732249 VL: 0.72612 A: 0.84375 D: 1.0 P: 0.0182513 C: 0.0\n",
      "L: 0.736715 VL: 0.690942 A: 0.89375 D: 1.0 P: 0.0191497 C: 0.0\n",
      "L: 0.723727 VL: 0.74038 A: 0.86875 D: 1.0 P: 0.0191278 C: 0.0\n",
      "L: 0.721169 VL: 0.706438 A: 0.8625 D: 1.0 P: 0.0140921 C: 0.0\n",
      "L: 0.727412 VL: 0.713091 A: 0.90625 D: 1.0 P: 0.0244167 C: 0.0\n",
      "L: 0.70919 VL: 0.700018 A: 0.85625 D: 1.0 P: 0.0181315 C: 0.0\n",
      "L: 0.719192 VL: 0.714349 A: 0.9 D: 1.0 P: 0.0635053 C: 0.0\n",
      "L: 0.728342 VL: 0.705702 A: 0.8625 D: 1.0 P: 0.0205527 C: 0.0\n",
      "L: 0.719512 VL: 0.72084 A: 0.875 D: 0.99375 P: 0.0221968 C: 0.0\n",
      "L: 0.717872 VL: 0.681929 A: 0.88125 D: 1.0 P: 0.040337 C: 0.0\n",
      "L: 0.710363 VL: 0.672629 A: 0.8875 D: 0.99375 P: 0.0113663 C: 0.0\n",
      "L: 0.707235 VL: 0.754764 A: 0.8625 D: 1.0 P: 0.0361287 C: 0.0\n",
      "L: 0.697589 VL: 0.735559 A: 0.86875 D: 1.0 P: 0.0140435 C: 0.0\n",
      "L: 0.713579 VL: 0.700359 A: 0.90625 D: 1.0 P: 0.0123556 C: 0.0\n",
      "L: 0.715463 VL: 0.746691 A: 0.85 D: 1.0 P: 0.01525 C: 0.0\n",
      "L: 0.719227 VL: 0.712202 A: 0.84375 D: 1.0 P: 0.0117119 C: 0.0\n",
      "L: 0.711272 VL: 0.697568 A: 0.88125 D: 1.0 P: 0.0359348 C: 0.0\n",
      "L: 0.711052 VL: 0.6936 A: 0.8625 D: 1.0 P: 0.0204159 C: 0.0\n",
      "L: 0.710026 VL: 0.713248 A: 0.83125 D: 1.0 P: 0.0173387 C: 0.0\n",
      "L: 0.718352 VL: 0.826417 A: 0.88125 D: 1.0 P: 0.015389 C: 0.0\n",
      "L: 0.712277 VL: 0.721332 A: 0.8625 D: 1.0 P: 0.0162808 C: 0.0\n",
      "L: 0.712996 VL: 0.777925 A: 0.81875 D: 1.0 P: 0.0465519 C: 0.0\n",
      "L: 0.706549 VL: 0.749925 A: 0.8125 D: 1.0 P: 0.0197695 C: 0.0\n",
      "L: 0.721051 VL: 0.683913 A: 0.8875 D: 1.0 P: 0.0222287 C: 0.0\n",
      "L: 0.710071 VL: 0.701485 A: 0.84375 D: 1.0 P: 0.0297622 C: 0.0\n",
      "L: 0.714699 VL: 0.769826 A: 0.8875 D: 1.0 P: 0.0184828 C: 0.0\n",
      "L: 0.702066 VL: 0.691829 A: 0.8875 D: 1.0 P: 0.0103896 C: 0.0\n",
      "L: 0.711127 VL: 0.685368 A: 0.85 D: 1.0 P: 0.0175698 C: 0.0\n",
      "L: 0.710114 VL: 0.759655 A: 0.875 D: 0.99375 P: 0.020729 C: 0.0\n",
      "L: 0.70605 VL: 0.721748 A: 0.8125 D: 1.0 P: 0.0100181 C: 0.0\n",
      "L: 0.723505 VL: 0.70841 A: 0.89375 D: 1.0 P: 0.0368245 C: 0.0\n",
      "L: 0.71803 VL: 0.71843 A: 0.83125 D: 1.0 P: 0.0154878 C: 0.0\n",
      "L: 0.718719 VL: 0.70506 A: 0.85625 D: 0.99375 P: 0.0313206 C: 0.0\n",
      "L: 0.724316 VL: 0.686135 A: 0.85625 D: 0.99375 P: 0.0313862 C: 0.0\n",
      "L: 0.716075 VL: 0.747124 A: 0.9125 D: 1.0 P: 0.0192719 C: 0.0\n",
      "L: 0.71492 VL: 0.766311 A: 0.86875 D: 1.0 P: 0.0129958 C: 0.0\n",
      "L: 0.728408 VL: 0.722226 A: 0.925 D: 1.0 P: 0.0116584 C: 0.0\n",
      "L: 0.723184 VL: 0.689338 A: 0.8375 D: 1.0 P: 0.0208023 C: 0.0\n",
      "L: 0.699169 VL: 0.768099 A: 0.825 D: 1.0 P: 0.0192007 C: 0.0\n",
      "L: 0.707924 VL: 0.719427 A: 0.8875 D: 1.0 P: 0.0320376 C: 0.0\n",
      "L: 0.704391 VL: 0.765781 A: 0.88125 D: 1.0 P: 0.0162807 C: 0.0\n",
      "L: 0.709668 VL: 0.71345 A: 0.8625 D: 1.0 P: 0.0154434 C: 0.0\n",
      "L: 0.701228 VL: 0.704755 A: 0.85625 D: 0.99375 P: 0.0278023 C: 0.0\n",
      "L: 0.713923 VL: 0.70313 A: 0.8375 D: 1.0 P: 0.0230312 C: 0.0\n",
      "L: 0.692692 VL: 0.701498 A: 0.825 D: 1.0 P: 0.0184176 C: 0.0\n",
      "L: 0.737867 VL: 0.759177 A: 0.8875 D: 1.0 P: 0.0192764 C: 0.0\n",
      "L: 0.705522 VL: 0.751712 A: 0.8625 D: 1.0 P: 0.024286 C: 0.0\n",
      "L: 0.704378 VL: 0.752396 A: 0.88125 D: 1.0 P: 0.0236301 C: 0.0\n",
      "L: 0.700407 VL: 0.750438 A: 0.9 D: 1.0 P: 0.053533 C: 0.0\n",
      "L: 0.712641 VL: 0.75176 A: 0.88125 D: 1.0 P: 0.0174011 C: 0.0\n",
      "L: 0.725985 VL: 0.758756 A: 0.8125 D: 1.0 P: 0.0247185 C: 0.0\n",
      "L: 0.717927 VL: 0.700787 A: 0.84375 D: 1.0 P: 0.0335389 C: 0.0\n",
      "L: 0.706769 VL: 0.759621 A: 0.8625 D: 1.0 P: 0.0190968 C: 0.0\n",
      "L: 0.707383 VL: 0.707992 A: 0.91875 D: 0.99375 P: 0.0344138 C: 0.0\n",
      "L: 0.703073 VL: 0.724006 A: 0.875 D: 1.0 P: 0.0166371 C: 0.0\n",
      "L: 0.708945 VL: 0.7525 A: 0.84375 D: 1.0 P: 0.0205827 C: 0.0\n",
      "L: 0.70873 VL: 0.832612 A: 0.9375 D: 1.0 P: 0.0361222 C: 0.0\n",
      "L: 0.717273 VL: 0.804745 A: 0.85625 D: 1.0 P: 0.0303085 C: 0.0\n",
      "L: 0.710127 VL: 0.71335 A: 0.9375 D: 1.0 P: 0.0388773 C: 0.0\n",
      "L: 0.72136 VL: 0.684602 A: 0.83125 D: 1.0 P: 0.0418749 C: 0.0\n",
      "L: 0.720786 VL: 0.695367 A: 0.85 D: 1.0 P: 0.0133919 C: 0.0\n",
      "L: 0.711628 VL: 0.723371 A: 0.90625 D: 0.99375 P: 0.0164443 C: 0.0\n",
      "L: 0.713618 VL: 0.719816 A: 0.8875 D: 0.99375 P: 0.0138201 C: 0.0\n",
      "L: 0.71848 VL: 0.686954 A: 0.88125 D: 1.0 P: 0.0162055 C: 0.0\n",
      "L: 0.706865 VL: 0.698112 A: 0.85625 D: 0.99375 P: 0.0246314 C: 0.0\n",
      "L: 0.707399 VL: 0.727328 A: 0.86875 D: 1.0 P: 0.0205179 C: 0.0\n",
      "L: 0.699107 VL: 0.694851 A: 0.85625 D: 1.0 P: 0.0145001 C: 0.0\n",
      "L: 0.712109 VL: 0.710567 A: 0.83125 D: 1.0 P: 0.0285671 C: 0.0\n",
      "L: 0.726363 VL: 0.725216 A: 0.825 D: 1.0 P: 0.0161816 C: 0.0\n",
      "L: 0.716682 VL: 0.713969 A: 0.84375 D: 1.0 P: 0.0174898 C: 0.0\n",
      "L: 0.699953 VL: 0.725729 A: 0.8375 D: 1.0 P: 0.0446662 C: 0.0\n",
      "L: 0.711048 VL: 0.716367 A: 0.8625 D: 1.0 P: 0.0163414 C: 0.0\n",
      "L: 0.724388 VL: 0.770054 A: 0.80625 D: 1.0 P: 0.0129682 C: 0.0\n",
      "L: 0.708298 VL: 0.730216 A: 0.85 D: 1.0 P: 0.0320326 C: 0.0\n",
      "L: 0.727244 VL: 0.737913 A: 0.86875 D: 1.0 P: 0.0190135 C: 0.0\n",
      "L: 0.716759 VL: 0.74604 A: 0.85625 D: 0.99375 P: 0.0288465 C: 0.0\n",
      "L: 0.698711 VL: 0.718245 A: 0.84375 D: 0.99375 P: 0.0404681 C: 0.0\n",
      "L: 0.706322 VL: 0.730896 A: 0.85625 D: 0.99375 P: 0.040841 C: 0.0\n",
      "L: 0.713502 VL: 0.704838 A: 0.81875 D: 1.0 P: 0.0273759 C: 0.0\n",
      "L: 0.694186 VL: 0.717072 A: 0.88125 D: 1.0 P: 0.0207184 C: 0.0\n",
      "L: 0.700952 VL: 0.715925 A: 0.8625 D: 1.0 P: 0.0210411 C: 0.0\n",
      "L: 0.704459 VL: 0.708236 A: 0.8875 D: 1.0 P: 0.0429708 C: 0.0\n",
      "L: 0.703637 VL: 0.706684 A: 0.8625 D: 1.0 P: 0.0288385 C: 0.0\n",
      "L: 0.692614 VL: 0.733456 A: 0.85 D: 1.0 P: 0.0560594 C: 0.0\n",
      "L: 0.710871 VL: 0.739363 A: 0.89375 D: 1.0 P: 0.0206486 C: 0.0\n",
      "L: 0.705444 VL: 0.735004 A: 0.86875 D: 1.0 P: 0.0109994 C: 0.0\n",
      "L: 0.709843 VL: 0.780117 A: 0.8875 D: 0.99375 P: 0.0167182 C: 0.0\n",
      "L: 0.713044 VL: 0.701675 A: 0.8875 D: 1.0 P: 0.0224938 C: 0.0\n",
      "L: 0.700085 VL: 0.715718 A: 0.8375 D: 1.0 P: 0.0211073 C: 0.0\n",
      "L: 0.695376 VL: 0.735096 A: 0.8375 D: 1.0 P: 0.0318539 C: 0.0\n",
      "L: 0.706871 VL: 0.771064 A: 0.84375 D: 1.0 P: 0.015305 C: 0.0\n",
      "L: 0.697507 VL: 0.737781 A: 0.86875 D: 1.0 P: 0.0317972 C: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 0.704 VL: 0.70137 A: 0.8875 D: 1.0 P: 0.0200565 C: 0.0\n",
      "L: 0.6905 VL: 0.709872 A: 0.88125 D: 0.99375 P: 0.0133752 C: 0.0\n",
      "L: 0.700526 VL: 0.780305 A: 0.84375 D: 1.0 P: 0.0368577 C: 0.0\n",
      "L: 0.702893 VL: 0.675788 A: 0.9 D: 1.0 P: 0.0133759 C: 0.0\n",
      "L: 0.71089 VL: 0.833526 A: 0.8625 D: 1.0 P: 0.0167987 C: 0.0\n",
      "L: 0.729767 VL: 0.711194 A: 0.81875 D: 1.0 P: 0.0261756 C: 0.0\n",
      "L: 0.724473 VL: 0.71956 A: 0.84375 D: 0.99375 P: 0.0302908 C: 0.0\n",
      "L: 0.7159 VL: 0.756767 A: 0.85 D: 1.0 P: 0.0576279 C: 0.0\n",
      "L: 0.70557 VL: 0.721408 A: 0.9 D: 1.0 P: 0.0254497 C: 0.0\n",
      "L: 0.715081 VL: 0.824028 A: 0.85 D: 1.0 P: 0.0277366 C: 0.0\n",
      "L: 0.712566 VL: 0.722891 A: 0.88125 D: 1.0 P: 0.0292751 C: 0.0\n",
      "L: 0.711326 VL: 0.727314 A: 0.8625 D: 0.99375 P: 0.0446924 C: 0.0\n",
      "L: 0.708368 VL: 0.730609 A: 0.85 D: 0.99375 P: 0.0264417 C: 0.0\n",
      "L: 0.712971 VL: 0.728414 A: 0.86875 D: 1.0 P: 0.0325392 C: 0.0\n",
      "L: 0.701005 VL: 0.74626 A: 0.8625 D: 1.0 P: 0.0158738 C: 0.0\n",
      "L: 0.697337 VL: 0.699339 A: 0.9125 D: 1.0 P: 0.0133163 C: 0.0\n",
      "L: 0.695448 VL: 0.752576 A: 0.85 D: 1.0 P: 0.0165373 C: 0.0\n",
      "L: 0.704178 VL: 0.696653 A: 0.83125 D: 1.0 P: 0.0264318 C: 0.0\n",
      "L: 0.730574 VL: 0.814982 A: 0.83125 D: 0.99375 P: 0.0253563 C: 0.0\n",
      "L: 0.703695 VL: 0.728979 A: 0.81875 D: 1.0 P: 0.0299079 C: 0.0\n",
      "L: 0.704925 VL: 0.724337 A: 0.86875 D: 0.99375 P: 0.0132309 C: 0.0\n",
      "L: 0.692467 VL: 0.688396 A: 0.85625 D: 1.0 P: 0.0268074 C: 0.0\n",
      "L: 0.708461 VL: 0.788702 A: 0.8625 D: 0.99375 P: 0.0815642 C: 0.0\n",
      "L: 0.715604 VL: 0.696486 A: 0.825 D: 1.0 P: 0.0459288 C: 0.0\n",
      "L: 0.713771 VL: 0.779311 A: 0.90625 D: 1.0 P: 0.0249887 C: 0.0\n",
      "L: 0.695871 VL: 0.738933 A: 0.83125 D: 1.0 P: 0.0315848 C: 0.0\n",
      "L: 0.714642 VL: 0.85709 A: 0.8625 D: 1.0 P: 0.0377577 C: 0.0\n",
      "L: 0.704153 VL: 0.752718 A: 0.84375 D: 1.0 P: 0.0159847 C: 0.0\n",
      "L: 0.69189 VL: 0.706576 A: 0.86875 D: 1.0 P: 0.0294854 C: 0.0\n",
      "L: 0.702589 VL: 0.706641 A: 0.83125 D: 1.0 P: 0.0324717 C: 0.0\n",
      "L: 0.690983 VL: 0.709165 A: 0.875 D: 0.99375 P: 0.0219049 C: 0.0\n",
      "L: 0.708037 VL: 0.734185 A: 0.8125 D: 1.0 P: 0.0205216 C: 0.0\n",
      "L: 0.703341 VL: 0.747735 A: 0.875 D: 0.99375 P: 0.017302 C: 0.0\n",
      "L: 0.694959 VL: 0.761834 A: 0.85625 D: 1.0 P: 0.0406648 C: 0.0\n",
      "L: 0.701198 VL: 0.713525 A: 0.86875 D: 1.0 P: 0.0231575 C: 0.0\n",
      "L: 0.708753 VL: 0.701122 A: 0.86875 D: 1.0 P: 0.0237477 C: 0.0\n",
      "L: 0.68885 VL: 0.738721 A: 0.825 D: 1.0 P: 0.0163396 C: 0.0\n",
      "L: 0.699101 VL: 0.698973 A: 0.85 D: 1.0 P: 0.0122071 C: 0.0\n",
      "L: 0.700999 VL: 0.728935 A: 0.85 D: 1.0 P: 0.0183344 C: 0.0\n",
      "L: 0.708293 VL: 0.795898 A: 0.88125 D: 1.0 P: 0.0258837 C: 0.0\n",
      "L: 0.689329 VL: 0.686299 A: 0.9 D: 1.0 P: 0.0157832 C: 0.0\n",
      "L: 0.680655 VL: 0.775085 A: 0.88125 D: 1.0 P: 0.0148667 C: 0.0\n",
      "L: 0.688988 VL: 0.729248 A: 0.81875 D: 1.0 P: 0.017661 C: 0.0\n",
      "L: 0.704275 VL: 0.738466 A: 0.83125 D: 1.0 P: 0.0367158 C: 0.0\n",
      "L: 0.693529 VL: 0.764392 A: 0.8125 D: 0.9875 P: 0.021878 C: 0.0\n",
      "L: 0.695838 VL: 0.759753 A: 0.89375 D: 1.0 P: 0.0194355 C: 0.0\n",
      "L: 0.68679 VL: 0.713699 A: 0.84375 D: 1.0 P: 0.0533117 C: 0.0\n",
      "L: 0.682459 VL: 0.712999 A: 0.89375 D: 0.99375 P: 0.0156417 C: 0.0\n",
      "L: 0.695501 VL: 0.741082 A: 0.88125 D: 1.0 P: 0.0267137 C: 0.0\n",
      "L: 0.683922 VL: 0.694368 A: 0.9125 D: 1.0 P: 0.0102604 C: 0.0\n",
      "L: 0.706139 VL: 0.687945 A: 0.8625 D: 0.9875 P: 0.043661 C: 0.0\n",
      "L: 0.683399 VL: 0.737758 A: 0.89375 D: 0.99375 P: 0.0186154 C: 0.0\n",
      "L: 0.691633 VL: 0.745488 A: 0.8625 D: 1.0 P: 0.0170059 C: 0.0\n",
      "L: 0.706656 VL: 0.733338 A: 0.84375 D: 1.0 P: 0.0271319 C: 0.0\n",
      "L: 0.688347 VL: 0.682347 A: 0.88125 D: 1.0 P: 0.0155578 C: 0.0\n",
      "L: 0.687207 VL: 0.720329 A: 0.8875 D: 1.0 P: 0.0200668 C: 0.0\n",
      "L: 0.703236 VL: 0.726384 A: 0.875 D: 1.0 P: 0.026981 C: 0.0\n",
      "L: 0.705653 VL: 0.735929 A: 0.775 D: 1.0 P: 0.0227494 C: 0.0\n",
      "L: 0.690265 VL: 0.712497 A: 0.875 D: 1.0 P: 0.0155633 C: 0.0\n",
      "L: 0.693142 VL: 0.739646 A: 0.88125 D: 1.0 P: 0.0213991 C: 0.0\n",
      "L: 0.696355 VL: 0.783214 A: 0.8625 D: 0.99375 P: 0.0479626 C: 0.0\n",
      "L: 0.700265 VL: 0.715042 A: 0.85625 D: 1.0 P: 0.0260138 C: 0.0\n",
      "L: 0.690283 VL: 0.712527 A: 0.90625 D: 1.0 P: 0.0193423 C: 0.0\n",
      "L: 0.693263 VL: 0.707613 A: 0.875 D: 1.0 P: 0.0183934 C: 0.0\n",
      "L: 0.693952 VL: 0.708714 A: 0.875 D: 1.0 P: 0.0162242 C: 0.0\n",
      "L: 0.708495 VL: 0.691489 A: 0.85625 D: 1.0 P: 0.0332987 C: 0.0\n",
      "L: 0.688841 VL: 0.749892 A: 0.85 D: 0.98125 P: 0.0237323 C: 0.0\n",
      "L: 0.688252 VL: 0.721886 A: 0.875 D: 1.0 P: 0.0150733 C: 0.0\n",
      "L: 0.713565 VL: 0.676582 A: 0.83125 D: 1.0 P: 0.0150342 C: 0.0\n",
      "L: 0.701144 VL: 0.68289 A: 0.84375 D: 1.0 P: 0.0215454 C: 0.0\n",
      "L: 0.701733 VL: 0.816243 A: 0.86875 D: 1.0 P: 0.0139086 C: 0.0\n",
      "L: 0.687729 VL: 0.688022 A: 0.85625 D: 1.0 P: 0.0408726 C: 0.0\n",
      "L: 0.680036 VL: 0.681902 A: 0.91875 D: 1.0 P: 0.0124946 C: 0.0\n",
      "L: 0.686193 VL: 0.71042 A: 0.89375 D: 0.9875 P: 0.0359956 C: 0.0\n",
      "L: 0.699532 VL: 0.685842 A: 0.8875 D: 0.99375 P: 0.0196174 C: 0.0\n",
      "L: 0.686492 VL: 0.681143 A: 0.88125 D: 0.99375 P: 0.0317622 C: 0.0\n",
      "L: 0.686365 VL: 0.668531 A: 0.88125 D: 1.0 P: 0.0148546 C: 0.0\n",
      "L: 0.703242 VL: 0.705679 A: 0.88125 D: 1.0 P: 0.0114626 C: 0.0\n",
      "L: 0.693406 VL: 0.719643 A: 0.90625 D: 1.0 P: 0.0298347 C: 0.0\n",
      "L: 0.679802 VL: 0.68616 A: 0.8875 D: 1.0 P: 0.0363152 C: 0.0\n",
      "L: 0.689382 VL: 0.732938 A: 0.85625 D: 1.0 P: 0.0096171 C: 0.0\n",
      "L: 0.691799 VL: 0.728851 A: 0.875 D: 0.99375 P: 0.0237076 C: 0.0\n",
      "L: 0.707554 VL: 0.703876 A: 0.93125 D: 0.99375 P: 0.0240458 C: 0.0\n",
      "L: 0.693942 VL: 0.757521 A: 0.8625 D: 1.0 P: 0.0138624 C: 0.0\n",
      "L: 0.686899 VL: 0.838989 A: 0.825 D: 1.0 P: 0.0452175 C: 0.0\n",
      "L: 0.698447 VL: 0.708048 A: 0.8375 D: 1.0 P: 0.0363093 C: 0.0\n",
      "L: 0.699169 VL: 0.693642 A: 0.81875 D: 1.0 P: 0.0304381 C: 0.0\n",
      "L: 0.699019 VL: 0.729548 A: 0.88125 D: 0.99375 P: 0.0133637 C: 0.0\n",
      "L: 0.696534 VL: 0.712827 A: 0.88125 D: 1.0 P: 0.0336683 C: 0.0\n",
      "L: 0.68736 VL: 0.768619 A: 0.84375 D: 1.0 P: 0.0210926 C: 0.0\n",
      "L: 0.710337 VL: 0.737455 A: 0.86875 D: 1.0 P: 0.0259215 C: 0.0\n",
      "L: 0.684369 VL: 0.710675 A: 0.8625 D: 1.0 P: 0.0119685 C: 0.0\n",
      "L: 0.683914 VL: 0.67486 A: 0.90625 D: 1.0 P: 0.0129478 C: 0.0\n",
      "L: 0.705478 VL: 0.706721 A: 0.85625 D: 1.0 P: 0.0127652 C: 0.0\n",
      "L: 0.689 VL: 0.777906 A: 0.875 D: 0.99375 P: 0.0173346 C: 0.0\n",
      "L: 0.698732 VL: 0.736103 A: 0.825 D: 1.0 P: 0.0455096 C: 0.0\n",
      "L: 0.705767 VL: 0.727122 A: 0.89375 D: 1.0 P: 0.0307651 C: 0.0\n",
      "L: 0.687757 VL: 0.725852 A: 0.9125 D: 1.0 P: 0.0107815 C: 0.0\n",
      "L: 0.683116 VL: 0.824499 A: 0.86875 D: 1.0 P: 0.0217923 C: 0.0\n",
      "L: 0.676596 VL: 0.685578 A: 0.875 D: 1.0 P: 0.0219061 C: 0.0\n",
      "L: 0.687073 VL: 0.731603 A: 0.8625 D: 1.0 P: 0.0322439 C: 0.0\n",
      "L: 0.684816 VL: 0.66627 A: 0.86875 D: 1.0 P: 0.0282145 C: 0.0\n",
      "L: 0.68665 VL: 0.703581 A: 0.8875 D: 1.0 P: 0.0206054 C: 0.0\n",
      "L: 0.687926 VL: 0.818177 A: 0.88125 D: 1.0 P: 0.0198907 C: 0.0\n",
      "L: 0.686182 VL: 0.736555 A: 0.89375 D: 1.0 P: 0.0304831 C: 0.0\n",
      "L: 0.686881 VL: 0.74511 A: 0.875 D: 1.0 P: 0.00939653 C: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/google/protobuf/internal/containers.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'value'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-55cf3927be4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_ac\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.85\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'assignment9a_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maction_ac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpos_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.tfg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/cs342/hw9/starter/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(output_file, graph, session)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtmp_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths, filename)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1170\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m           \u001b[0mrestore_sequentially\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_sequentially\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m           filename=self._filename)\n\u001b[0m\u001b[1;32m   1173\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0msave_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AddSaveOps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         restore_op = self._AddRestoreOps(filename_tensor, saveables,\n\u001b[0;32m--> 688\u001b[0;31m                                          restore_sequentially, reshape)\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;31m# In the following use case, it's possible to have restore_ops be called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_AddRestoreOps\u001b[0;34m(self, filename_tensor, saveables, restore_sequentially, reshape, preferred_shard, name)\u001b[0m\n\u001b[1;32m    405\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_cpu0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaveable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msaveable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_control_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m           \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_shard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m           \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore_op\u001b[0;34m(self, filename_tensor, saveable, preferred_shard)\u001b[0m\n\u001b[1;32m    245\u001b[0m               \u001b[0;34m[\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m               \u001b[0;34m[\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_spec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m               [spec.tensor.dtype])[0])\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, dtypes, name)\u001b[0m\n\u001b[1;32m    661\u001b[0m                                 \u001b[0mtensor_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                                 \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                                 dtypes=dtypes, name=name)\n\u001b[0m\u001b[1;32m    664\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    491\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                          as_ref=False):\n\u001b[1;32m    120\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n\u001b[1;32m    105\u001b[0m       \u001b[0;34m\"Const\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2593\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2595\u001b[0;31m     \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_NodeDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m     \u001b[0;31m# Apply any additional attributes requested. Do not overwrite any existing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_NodeDef\u001b[0;34m(op_type, name, device, attrs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m       \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/google/protobuf/internal/containers.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m       \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key_checker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m       \u001b[0mnew_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m       \u001b[0mnew_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SetListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_listener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_present_in_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage_listener_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNullMessageListener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listener_for_children\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Listener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m       \u001b[0mfield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_GetFieldByName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_descriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent_message)\u001b[0m\n\u001b[1;32m   1385\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_message_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_message_weakref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0;31m# As an optimization, we also indicate directly on the listener whether\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Set up training\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Run the training for some iterations\n",
    "for it in range(500):\n",
    "    sess.run(switch_train_op)\n",
    "\n",
    "    loss_vals = []\n",
    "    # Run 10 training iterations and 1 validation iteration\n",
    "    for i in range(10):\n",
    "        #sess.run(action_loss)\n",
    "        #sess.run(is_dying_loss)\n",
    "        #sess.run(position_loss)\n",
    "        #sess.run(coins_loss)\n",
    "        loss_val = sess.run([loss,action_loss,is_dying_loss,position_loss,coins_loss,opt])[:-1]\n",
    "        loss_vals.append(loss_val)\n",
    "    # Compute the summary\n",
    "    mean_loss = np.mean(np.array(loss_vals), axis=0)\n",
    "    summary = {n+':0':mean_loss[i] for i, n in enumerate(['loss','action_loss','is_dying_loss','position_loss','coins_loss'])}\n",
    "\n",
    "    # Compute the validation loss\n",
    "    sess.run(switch_valid_op)\n",
    "    loss_val = sess.run(loss)\n",
    "    summary['val_loss:0'] = loss_val\n",
    "    \n",
    "    summary_writer.add_summary( sess.run(merged_summary, summary), it )\n",
    "\n",
    "    # Let's update tensorboard\n",
    "    #action prediction 90% accuracy = 25pts\n",
    "    #death prediction 100% accuracy = 25pts\n",
    "    #pos prediction L2=0.25 = 25pts\n",
    "    #coins prediction L2=0.01 = 25pts\n",
    "    #print('[%3d] Loss: %0.3f  \\t  val loss A.: %0.3f'%(it, mean_loss[0], loss_val))\n",
    "    if (it%1 == 0):\n",
    "        sess.run(switch_valid_op)\n",
    "        action_ac, dying_ac, pos_loss, coin_loss = sess.run([action_acc, dying_acc, position_loss, coins_loss])\n",
    "        print('L: ' + str(mean_loss[0]) + ' VL: '+ str(loss_val) + ' A: '+ str(action_ac)+' D: '+ str(dying_ac)+' P: '+ str(pos_loss)+' C: '+ str(coin_loss))\n",
    "        if(action_ac > 0.85):\n",
    "            name = 'assignment9a_' + str(int(100 * action_ac)) + '_' + str(int(1000 * pos_loss)) + '.tfg'\n",
    "            util.save(name, session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Evaluation\n",
    "### Compute the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(switch_valid_op)\n",
    "action_ac, dying_ac, pos_loss, coin_loss = sess.run([action_acc, dying_acc, position_loss, coins_loss])\n",
    "\n",
    "print('Action prediction accuracy: ' + str(action_ac))\n",
    "print('Dying prediction accuracy: ' + str(dying_ac))\n",
    "print('Position prediction L2: ' + str(pos_loss))\n",
    "print('Coin prediction L2: ' + str(coin_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Save Model\n",
    "Please note that we also want you to turn in your ipynb for this assignment.  Zip up the ipynb along with the tfg for your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util.save('assignment9.tfg', session=sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
