{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4\n",
    "\n",
    "Today:\n",
    "<ul>\n",
    "<li>Convolutions</li>\n",
    "<li>Pooling</li>\n",
    "<li>TensorBoard</li>\n",
    "</ul>\n",
    "\n",
    "<em>Some code from tensorflow.org documentation.</em>\n",
    "\n",
    "## Extra Resources\n",
    "<ul>\n",
    "<li><a href='https://www.tensorflow.org/api_docs/python/tf/name_scope'>TF Name Scoping</a></li>\n",
    "<li><a href='http://cs231n.github.io/convolutional-networks/'>CS 231n Notes on CNNs</a></li>\n",
    "</ul>\n",
    "\n",
    "## TF Convolutions and Pooling\n",
    "<a href='https://www.tensorflow.org/tutorials/layers'>A Guide to TF Layers: Building a Convolutional Neural Network</a><br/>\n",
    "<a href='https://www.tensorflow.org/versions/r1.3/api_docs/python/tf/layers/conv2d'>tf.layers.conv2d</a><br/>\n",
    "<a href='https://www.tensorflow.org/api_docs/python/tf/layers/max_pooling2d'>tf.layers.max_pooling2d</a><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and load data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def load(filename, W=64, H=64):\n",
    "    data = np.fromfile(filename, dtype=np.uint8).reshape((-1, W*H*3+1))\n",
    "    images, labels = data[:, :-1].reshape((-1,H,W,3)), data[:, -1]\n",
    "    return images, labels\n",
    "\n",
    "train_image_data, train_label_data = load('tux_train.dat')\n",
    "val_image_data, val_label_data = load('tux_val.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv1/Relu:0\", shape=(?, 32, 32, 20), dtype=float32)\n",
      "Tensor(\"pool1/MaxPool:0\", shape=(?, 16, 16, 20), dtype=float32)\n",
      "Tensor(\"conv2/Relu:0\", shape=(?, 8, 8, 64), dtype=float32)\n",
      "Tensor(\"pool2/MaxPool:0\", shape=(?, 4, 4, 64), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"fully_connected/Relu:0\", shape=(?, 1024), dtype=float32)\n",
      "Tensor(\"fully_connected_1/Relu:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "<tensorflow.python.training.adam.AdamOptimizer object at 0x12a87d610>\n",
      "name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_conv1/weights/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1/biases/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2/weights/ApplyAdam\"\n",
      "input: \"^Adam/update_conv2/biases/ApplyAdam\"\n",
      "input: \"^Adam/update_fully_connected/weights/ApplyAdam\"\n",
      "input: \"^Adam/update_fully_connected/biases/ApplyAdam\"\n",
      "input: \"^Adam/update_fully_connected_1/weights/ApplyAdam\"\n",
      "input: \"^Adam/update_fully_connected_1/biases/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# Let's build our first CNN\n",
    "I = tf.placeholder(tf.float32, (None, 64, 64, 3))\n",
    "white_inputs = (I - 100.) / 72.\n",
    "labels = tf.placeholder(tf.int64, (None))\n",
    "\n",
    "# Convolutional Layer #1\n",
    "conv1 = tf.contrib.layers.conv2d(\n",
    "  inputs=white_inputs,\n",
    "  num_outputs=20,\n",
    "  kernel_size=[5, 5],\n",
    "  stride=2,\n",
    "  padding=\"same\",\n",
    "  scope='conv1')\n",
    "print(conv1)\n",
    "\n",
    "# Pooling Layer #1\n",
    "pool1 = tf.contrib.layers.max_pool2d(inputs=conv1, kernel_size=[2, 2], stride=2, scope='pool1')\n",
    "print(pool1)\n",
    "\n",
    "# Convolutional Layer #2\n",
    "conv2 = tf.contrib.layers.conv2d(\n",
    "    inputs=pool1,\n",
    "    num_outputs=64,\n",
    "    kernel_size=[5, 5],\n",
    "    stride=2,\n",
    "    padding=\"same\",\n",
    "    scope='conv2')\n",
    "print(conv2)\n",
    "\n",
    "# Pooling Layer #2\n",
    "pool2 = tf.contrib.layers.max_pool2d(inputs=conv2, kernel_size=[2, 2], stride=2, scope='pool2')\n",
    "print(pool2)\n",
    "\n",
    "# Flatten pooled features\n",
    "pool2_flat = tf.reshape(pool2, [-1, np.prod(pool2.get_shape().as_list()[1:])])\n",
    "print(pool2_flat)\n",
    "\n",
    "dense = tf.contrib.layers.fully_connected(inputs=pool2_flat, num_outputs=1024, activation_fn=tf.nn.relu)\n",
    "print(dense)\n",
    "\n",
    "# Logits Layer\n",
    "logits = tf.contrib.layers.fully_connected(inputs=dense, num_outputs=10)\n",
    "print(logits)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits,1), labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "print(loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.001, 0.9, 0.999)\n",
    "print(optimizer)\n",
    "\n",
    "train_op = optimizer.minimize(loss)\n",
    "print(train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard\n",
    "<a href='https://www.tensorflow.org/get_started/summaries_and_tensorboard'>TensorBoard Introduction</a><br/>\n",
    "<a href='https://www.tensorflow.org/api_guides/python/summary'>Summary variables</a><br/>\n",
    "<a href='https://www.tensorflow.org/api_docs/python/tf/summary/merge_all'>merge_all</a><br/>\n",
    "<a href='https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter'>FileWriter</a><br/>\n",
    "<a href='https://research.googleblog.com/2017/09/build-your-own-machine-learning.html'>New TensorBoard API</a><br/><br/>\n",
    "Let's use the graph we used when introducing convolutions but now add summary operations so we can see the graph and monitor training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's set up TensorBoard\n",
    "train_writer = tf.summary.FileWriter('/tmp/section4/train', sess.graph)\n",
    "validation_writer = tf.summary.FileWriter('/tmp/section4/validation')\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some summary operations\n",
    "acc = tf.summary.scalar('Accuracy', accuracy)\n",
    "\n",
    "# Add visualizations of our 1st layers weights\n",
    "with tf.variable_scope('conv1') as scope:\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    weights = tf.get_variable('weights')\n",
    "    tf.summary.image('filters', tf.transpose(weights, [3, 0, 1, 2]), max_outputs=10)\n",
    "    tf.summary.histogram('filters', tf.get_variable('weights'))\n",
    "\n",
    "# Check the distribution on our outputs\n",
    "tf.summary.histogram('outputs', logits)\n",
    "        \n",
    "# Merge them together\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start TensorBoard from the command line\n",
    "# tensorboard --logdir=/tmp/section4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy at epoch 0: 0.644683\n",
      "Validation accuracy at epoch 1: 0.65363\n",
      "Validation accuracy at epoch 2: 0.776841\n",
      "Validation accuracy at epoch 3: 0.83589\n",
      "Validation accuracy at epoch 4: 0.846626\n",
      "Validation accuracy at epoch 5: 0.832566\n",
      "Validation accuracy at epoch 6: 0.830266\n",
      "Validation accuracy at epoch 7: 0.840491\n",
      "Validation accuracy at epoch 8: 0.83001\n",
      "Validation accuracy at epoch 9: 0.848159\n",
      "Validation accuracy at epoch 10: 0.836656\n",
      "Validation accuracy at epoch 11: 0.854294\n",
      "Validation accuracy at epoch 12: 0.856595\n",
      "Validation accuracy at epoch 13: 0.861963\n",
      "Validation accuracy at epoch 14: 0.865031\n",
      "Validation accuracy at epoch 15: 0.851483\n",
      "Validation accuracy at epoch 16: 0.856339\n",
      "Validation accuracy at epoch 17: 0.858384\n",
      "Validation accuracy at epoch 18: 0.855828\n",
      "Validation accuracy at epoch 19: 0.871421\n"
     ]
    }
   ],
   "source": [
    "# Train your network and watch it on TensorBoard\n",
    "BS = 32\n",
    "train_count = 0\n",
    "for epoch in range(20):\n",
    "    np.random.seed(epoch)\n",
    "    np.random.shuffle(train_image_data)\n",
    "    np.random.seed(epoch)\n",
    "    np.random.shuffle(train_label_data)\n",
    "    # Train\n",
    "    # Go through the entire dataset once\n",
    "    for i in range(0, train_image_data.shape[0]-BS+1, BS):\n",
    "        # Train a single batch\n",
    "        batch_images, batch_labels = train_image_data[i:i+BS], train_label_data[i:i+BS]\n",
    "        summary, _ = sess.run([merged, train_op], feed_dict={I: batch_images, labels: batch_labels})\n",
    "        train_writer.add_summary(summary, train_count)\n",
    "        train_count += 1\n",
    "    validation_writer.flush()\n",
    "    train_writer.flush()\n",
    "    # Validation Accuracy\n",
    "    summary, acc = sess.run([merged, accuracy], feed_dict={I: val_image_data, labels: val_label_data})\n",
    "    validation_writer.add_summary(summary, train_count)\n",
    "    print('Validation accuracy at epoch %s: %s' % (epoch, acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
