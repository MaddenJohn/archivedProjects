{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7\n",
    "\n",
    "### Today\n",
    "<ul>\n",
    "<li><a href='https://www.tensorflow.org/versions/master/api_docs/python/tf/data/TFRecordDataset'>TensorFlow Datasets</a></li>\n",
    "<li>Fully Convolutional Networks</li>\n",
    "<li><a href='https://www.tensorflow.org/api_docs/python/tf/image'>Up-Convolutions</a></li>\n",
    "<li><a href='https://www.tensorflow.org/api_docs/python/tf/layers/conv2d'>Skip Connections</a></li>\n",
    "</ul>\n",
    "\n",
    "### Related Reading\n",
    "<ul>\n",
    "<li><a href='https://distill.pub/2016/deconv-checkerboard/'>Deconvolution Vizualation</a></li>\n",
    "<li><a href='https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf'>Fully Convolutional Networks for Semantic Segmentation</a></li>\n",
    "<li><a href='https://arxiv.org/pdf/1603.07285v1.pdf'>A guide to convolution arithmetic for deep\n",
    "learning</a></li>\n",
    "<li><a href='http://www.matthewzeiler.com/wp-content/uploads/2017/07/cvpr2010.pdf'>Deconvolutional Networks</a></li>\n",
    "<li><a href='https://www.tensorflow.org/programmers_guide/datasets'>TensorFlow Programmers Guide on Importing Data</a> - focuses on newer Dataset API tf.contrib.data.Dataset (not what we are using for now but has a similar API).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets - <a href='https://www.tensorflow.org/versions/master/api_docs/python/tf/data/TFRecordDataset'>tf.data.TFRecordDataset</a>\n",
    "\"The TFRecord file format is a simple record-oriented binary format that many TensorFlow applications use for training data. The tf.contrib.data.TFRecordDataset class enables you to stream over the contents of one or more TFRecord files as part of an input pipeline.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parser(record):\n",
    "    # Parse the TF record\n",
    "    parsed = tf.parse_single_example(record, features={\n",
    "       'height': tf.FixedLenFeature([], tf.int64),\n",
    "       'width': tf.FixedLenFeature([], tf.int64),\n",
    "       'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "       'label_raw': tf.FixedLenFeature([], tf.string)\n",
    "    })\n",
    "    # Load the data and format it\n",
    "    H = tf.cast(parsed['height'], tf.int32)\n",
    "    W = tf.cast(parsed['width'], tf.int32)\n",
    "    image = tf.reshape(tf.decode_raw(parsed[\"image_raw\"], tf.uint8), [H,W,3])\n",
    "    label = tf.reshape(tf.decode_raw(parsed[\"label_raw\"], tf.uint8), [H,W])\n",
    "    # Perform additional preprocessing on the parsed data.\n",
    "    return image, label\n",
    "\n",
    "def data_augmentation(image, label):\n",
    "    # TODO: Apply some data augmentation, namely cropping and mirroring for faster training\n",
    "    return image, label\n",
    "\n",
    "def load_dataset(tfrecord, augment=True):\n",
    "    # Load the dataset\n",
    "    dataset = tf.contrib.data.TFRecordDataset(tfrecord)\n",
    "\n",
    "    # Parse the tf record entries\n",
    "    dataset = dataset.map(parser)\n",
    "    if augment:\n",
    "        dataset = dataset.map(data_augmentation)\n",
    "\n",
    "    # Shuffle the data, batch it and run this for multiple epochs\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(32)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset\n",
    "\n",
    "# Lets clear the tensorflow graph, so that you don't have to restart the notebook every time you change the network\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train_data = load_dataset('train.tfrecord')\n",
    "valid_data = load_dataset('valid.tfrecord')\n",
    "\n",
    "# Create an iterator for the datasets\n",
    "# The iterator allows us to quickly switch between training and validataion\n",
    "iterator = tf.contrib.data.Iterator.from_structure(train_data.output_types,train_data.output_shapes)\n",
    "\n",
    "# and fetch the next images from the dataset (every time next_image is evaluated a new image set of 32 images is returned)\n",
    "next_image, next_label = iterator.get_next()\n",
    "\n",
    "# Define operations that switch between train and valid\n",
    "switch_train_op = iterator.make_initializer(train_data)\n",
    "switch_valid_op = iterator.make_initializer(valid_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Convolutional Networks (FCNs)\n",
    "<b>Key Idea</b>: Whole Image Inputs -- Whole Image Ground Truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, 64, 64, 3), dtype=float32)\n",
      "Tensor(\"Conv/Relu:0\", shape=(?, 32, 32, 30), dtype=float32)\n",
      "Tensor(\"Conv2d_transpose/Relu:0\", shape=(?, 64, 64, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.placeholder(tf.float32, (None, 64, 64, 3))\n",
    "print(inputs)\n",
    "\n",
    "# Up-Convolution\n",
    "h = tf.contrib.layers.conv2d(inputs, num_outputs=30, kernel_size=(5, 5), stride=(2, 2))\n",
    "print(h)\n",
    "\n",
    "output = tf.contrib.layers.conv2d_transpose(h, num_outputs=3, kernel_size=(5, 5), stride=(2, 2))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FCN as a Convolutional Auto-encoder\n",
    "loss = tf.reduce_mean((inputs - output) ** 2)\n",
    "opt = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "# Get your favorite images\n",
    "def load(filename, W=64, H=64):\n",
    "    data = np.fromfile(filename, dtype=np.uint8).reshape((-1, W*H*3+1))\n",
    "    images, labels = data[:, :-1].reshape((-1,H,W,3)), data[:, -1]\n",
    "    return images, labels\n",
    "\n",
    "image_data, label_data = load('tux_train.dat')\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for e in range(1000):\n",
    "    sess.run(opt, feed_dict={inputs: image_data[0:5]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip Connections\n",
    "\"Combining fine layers and coarse layers lets the model make local predictions that respect global structure.\" - <a href='https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf'>Fully Convolutional Networks for Semantic Segmentation</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1: Tensor(\"Conv_4/Relu:0\", shape=(?, 16, 16, 30), dtype=float32)\n",
      "h2: Tensor(\"Conv_5/Relu:0\", shape=(?, 8, 8, 20), dtype=float32)\n",
      "h3: Tensor(\"Conv_6/Relu:0\", shape=(?, 4, 4, 10), dtype=float32)\n",
      "\n",
      "h1: Tensor(\"Conv2d_transpose_6/Relu:0\", shape=(?, 8, 8, 10), dtype=float32)\n",
      "h1_skip: Tensor(\"Conv2d_transpose_7/Relu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "h2: Tensor(\"Conv2d_transpose_8/Relu:0\", shape=(?, 16, 16, 20), dtype=float32)\n",
      "h2_skip: Tensor(\"Conv2d_transpose_9/Relu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "h3: Tensor(\"Conv2d_transpose_10/Relu:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "\n",
      "output: Tensor(\"add_3:0\", shape=(?, 32, 32, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Use tensors of same shape and add\n",
    "inputs = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "\n",
    "h = tf.contrib.layers.conv2d(inputs, num_outputs=30, kernel_size=(5, 5), stride=(2, 2))\n",
    "print('h1: ' + str(h))\n",
    "\n",
    "h = tf.contrib.layers.conv2d(h, num_outputs=20, kernel_size=(5, 5), stride=(2, 2))\n",
    "print('h2: ' + str(h))\n",
    "\n",
    "h = tf.contrib.layers.conv2d(h, num_outputs=10, kernel_size=(5, 5), stride=(2, 2))\n",
    "print('h3: ' + str(h))\n",
    "print('')\n",
    "\n",
    "h1 = tf.contrib.layers.conv2d_transpose(h, num_outputs=10, kernel_size=(5, 5), stride=(2, 2))\n",
    "h1_skip = tf.contrib.layers.conv2d_transpose(h, num_outputs=3, kernel_size=(5, 5), stride=(8, 8))\n",
    "# change kernal size to 8,8 or add more skips \n",
    "print('h1: ' + str(h1))\n",
    "print('h1_skip: ' + str(h1_skip) + '\\n')\n",
    "\n",
    "h2 = tf.contrib.layers.conv2d_transpose(h1, num_outputs=20, kernel_size=(5, 5), stride=(2, 2))\n",
    "h2_skip = tf.contrib.layers.conv2d_transpose(h2, num_outputs=3, kernel_size=(5, 5), stride=(2, 2))\n",
    "print('h2: ' + str(h2))\n",
    "print('h2_skip: ' + str(h2_skip) + '\\n')\n",
    "\n",
    "h3 = tf.contrib.layers.conv2d_transpose(h2, num_outputs=3, kernel_size=(5, 5), stride=(2, 2))\n",
    "print('h3: ' + str(h3) + '\\n')\n",
    "\n",
    "output = h3 + h2_skip + h1_skip\n",
    "print('output: ' + str(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option 2: Use tensors of different shapes and add\n",
    "inputs = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "\n",
    "h = tf.contrib.layers.conv2d(inputs, num_outputs=30, kernel_size=(5, 5), stride=(2, 2))\n",
    "print('h1: ' + str(h))\n",
    "\n",
    "h = tf.contrib.layers.conv2d(h, num_outputs=20, kernel_size=(5, 5), stride=(2, 2))\n",
    "print('h2: ' + str(h))\n",
    "\n",
    "h = tf.contrib.layers.conv2d(h, num_outputs=10, kernel_size=(5, 5), stride=(2, 2))\n",
    "print('h3: ' + str(h))\n",
    "print('')\n",
    "\n",
    "h1 = tf.contrib.layers.conv2d_transpose(h, num_outputs=10, kernel_size=(5, 5), stride=(2, 2))\n",
    "h1_skip = tf.contrib.layers.conv2d_transpose(h, num_outputs=10, kernel_size=(5, 5), stride=(8, 8))\n",
    "print('h1: ' + str(h))\n",
    "print('h1_skip: ' + str(h1_skip) + '\\n')\n",
    "\n",
    "h2 = tf.contrib.layers.conv2d_transpose(h1, num_outputs=20, kernel_size=(5, 5), stride=(2, 2))\n",
    "h2_skip = tf.contrib.layers.conv2d_transpose(h2, num_outputs=10, kernel_size=(5, 5), stride=(2, 2))\n",
    "print('h2: ' + str(h2))\n",
    "print('h2_skip: ' + str(h2_skip) + '\\n')\n",
    "\n",
    "h3 = tf.contrib.layers.conv2d_transpose(h2, num_outputs=3, kernel_size=(5, 5), stride=(2, 2))\n",
    "print('h3: ' + str(h3) + '\\n')\n",
    "\n",
    "filter_concat = tf.concat([h1_skip, h2_skip, h3], axis=-1)\n",
    "print('filter_concat: ' + str(filter_concat))\n",
    "\n",
    "output = tf.contrib.layers.conv2d(filter_concat, num_outputs=3, kernel_size=(1, 1), stride=(1, 1))\n",
    "print('output: ' + str(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
